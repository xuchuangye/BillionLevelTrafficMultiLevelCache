# 应用保护



## 应用保护概述

系统边界经常发生故障，A系统，B系统，A调用B总是出问题，把这种故障定义为系统边界故障



系统压力太大，负载太高

请求多了，最常见的就是数据库慢查询，或者数据库慢查询导致读写异常，或者导致其它服务没有办法连接数据库，响应特别慢

系统内部原因：bug

系统外部原因：黑客攻击



应用保护的核心思想：优先保证核心业务，优先保证绝大部分用户



## 降级（系统内部）

系统自降一级，提供的功能减少

对熔断来说，降级是系统内部让自己执行一些操作来防止自己出问题，弃车保帅

对限流来说，降级是系统根据功能的优先级进行考虑

系统将某些业务和功能降低、减弱，只提供部分功能，也可以全部停掉



举例：

论坛的主要核心业务是用户查看帖子，而用户发帖子不是最核心的，降级就是将用户发帖子的功能给停掉，让给用户看帖子的



### 降级的思想

降级的思想：把不核心的功能干掉，只留下核心功能。保证核心业务



### 降级的方式

1.系统提供后门接口（修改某个服务或者某个方法的开关）

在系统中提供一个接口，接口中定义降级的方法或者系统，当管理员访问这个接口的地址时，执行这个接口，将方法或者系统通过接口传入到系统里面。

可以判断一下，如果不请求后门接口，方法正常执行，如果请求后门接口，某个方法不执行

在程序里面，调用某一个方法之前判断一下，这个方法该不该执行



缺点：

如果被黑客利用，那就尴尬了，系统天天都处于降级的状态

如果系统比较多，需要一个一个执行，就会非常麻烦

应用场景：

刚做出来的系统，运行一段时间之后，访问量特别高，系统扛不住，需要降级的时候临时的一种措施

2.独立的降级系统，对后门接口的封装（修改某个服务或者某个方法的开关）

开发一个独立的系统，有漂亮的界面，可以进行复杂权限的管理，批量的控制判断条件，独立系统一般通过Redis实现

```
if(ifXxxList) {
	getXxxList();
} else {
	getXxxList备用();
}
```



前提：代码提前规划好，哪些需要降级，哪些不需要降级，并且如果代码业务是核心功能的还不能停用

应用场景：

新开发的上线后的系统要做灰度测试，不能保证百分之百新上线功能的正确性，所以需要设置开关，当新上线的服务出现故障时，可以及时的关闭，不影响到正常的流程



### 自动开关降级

提前写好降级逻辑，让代码自动触发去执行降级的流程



1.触发降级的条件：

-   超时（考虑阈值，分布式系统能够容忍网络的不可靠），访问数据库的服务很慢，HTTP请求的服务很慢，且该服务不是核心服务，超时可以设置阈值
-   举例：
    -   超过1s你没有响应，就把你降级掉，下次再来访问就不让它访问你了，访问我的备用方法
    -   我调用你一次，超时5s，我在Redis中设置一个key，下次请求再来查询这个key，如果key有或者这个key标记你超时了，那就走另外一个方法，就不走调用你的这个方法
-   异常（考虑阈值，分布式系统能够容忍网络的不可靠），我们对系统的异常有一个明确的包装
-   限流，
-   举例：
    -   订单服务，访问量太大，系统扛不住，请求降级，不是自己把我自己关闭掉，而是我自己在我前面触发一个东西
    -   别人访问我，我的系统压力已经很大了，我有一个阈值，1s之内1000个请求，达到1000个请求，我就要触发阈值，把下次来的请求先缓存起来，再缓存1000个请求
    -   我是一个服务，你来调用我，我有一个阈值，1s之内处理1000请求，但是此时已经达到1000个请求，我这个系统不能硬去处理，否则系统会崩溃。我让你们再来的请求先等着，给你1000个请求的缓冲队列，这个队列还能容忍1000个，超过1000个我就直接拒绝
    -   这种降级跟线程池的拒绝策略很像



### 降级的手段

减少不必要的操作，保留核心业务功能

1.   停止读取数据库，从缓存中去读取，准确结果转为近似结果

举例：

视频网站，看高清的人太多了，高清转为流畅

定位系统，不用高精度定位，转为基站定位，把定位不是那么精准，模糊一些，让响应速度快一些

2.   返回静态结果，需要去数据库查询做一些很复杂的计算，结果系统降级，你不调用了，也需要返回一个结果，给一个默认页面

举例：

猜你喜欢，本来是个性化推荐，现在系统降级了，不去访问了，给一个默认的，每一个人看到的都一样

3.   同步转异步（写多读少），系统忙不过来，尤其是写一大堆数据，忙不过来，先放到消息队列中，至于什么时候写，再慢慢说

4.   功能裁剪，类似于将猜你喜欢，热榜推荐这种推荐性的功能给干掉

5.   禁止写操作，系统运行高峰期，不允许修改用户的个人信息，数据库的压力本来就更大了，你还来施加写的操作的压力，那我就禁止写的操作

举例：

双十一或者春晚这种高峰期，不让修改个人信息这种写操作，以后再说，先扛过去高峰期

6.   分用户降级，针对不同的用户采取不同的降级策略

举例：

网站放出去，肯定会有用户爬数据，我们封杀爬虫

平时爬数据对我们的网站排名还是有好处的，那我就让你爬了

但是如果业务高峰期，爬虫会影响业务的正常开展，那肯定要封杀爬虫

但是封爬虫有可能会误杀，一个ip来了多次我就把它封掉，或者一次操作了多个页面我也把它封掉，但是宁可错杀也要保证大部分人都能用

7.   工作量证明，POW，给你增加工作量，你才能使用我的系统；给你使用我的系统增加点难度，就能把我系统的压力降低，比如：验证码，数学题，拼图，滑块

举例：

买火车票，地铁早高峰，都需要绕路，这个绕路的过程就是增加工作量



## 熔断（系统外部）

我依赖了外部系统，因为外部系统总出问题，我不得已打开熔断的开关，我不调用了

举例：

A服务：X功能 调用 B服务： T接口

如果T接口的响应速度过慢，必然会导致A服务的X功能肯定会被拖慢，进一步导致A服务其它线程卡住，X功能好久都没有响应，在服务器中越堆积越多，A服务的其他功能都提供不了了

这时候A服务的X功能就要进行熔断



阈值怎么定？首先进行预估，然后需要上线观察，最后具体调优，以实际情况为准



### 熔断的策略

熔断是调用方去做，当调用方去请求提供方时，如果请求的失败率达到阈值或者平均的响应时间达到阈值，就会开启熔断的开关

![image-20230309101714343](%E5%BA%94%E7%94%A8%E4%BF%9D%E6%8A%A4.assets/image-20230309101714343.png)



1.根据请求的失败率：熔断开关 打开

半开状态（快速失败 Fail Fast）过一段时间，再将熔断开关 关闭，放进去一个请求，如果失败，熔断开关 再次打开

举例：

对于客户端调用某个服务，如果服务在短时间内大量超时或者抛错，则客户端熔断

Hystrix：yaml配置文件，每当20个请求，失败率达到50%时，熔断开关 打开，过5s之后，熔断开关 关闭，放进去一个请求，如果成功，熔断开关保持关闭，如果失败，熔断开关 再次打开



2.根据响应时间做熔断：当资源平均响应时间超过阈值时，资源进入准降级的状态，如果接下来的请求的响应时间还是超过该阈值，那么进行熔断

举例：

Sentinel，当平均响应时间大于50ms，并且接下来持续5个请求的响应时间都超过50ms，熔断将开启，5000ms后，熔断再次关闭



## 限流



对降级来说，限流是从用户访问的压力的角度来考虑如何应对故障

限流只允许系统能够承受的访问量超出系统访问能力的请求，就被丢弃或者拒绝，保证系统正常持续的运行

举例：

系统1s之内只能承受10个请求，结果1s来了20个请求，系统承受不了，后面的请求直接丢弃或者拒绝，保证系统持续的运行

### 限流的原因

#### 从系统外部的角度：基于请求的限流

请求太多了



限流的方式：

1.   限制请求的总量（阈值）

直播间只能容纳100人同时观看，超过的只能请出去

2.   限制时间量（阈值）

一个时间窗口内，比如：在1s内只接纳100个请求，在1s内超出的请求都拒绝，也就是第100请求之后的请求都拒绝



注意事项：阈值还是需要提前压测，长期的上线观察和调优

举例：

B接口设置1s内能够承受10000个请求，结果上线发现1s内承受5000个请求都快要扛不住了，因为压测没有线上的环境复杂，压测只压测一个接口：B，结果上线之后，有请求调用A接口，有请求调用B接口，有请求调用C接口，有请求调用D接口，结果B接口承受5000个请求的时候已经快要扛不住了

所以阈值会有一个上线观察，长期调优的过程



##### 延伸扩展：排队

限流：是直接拒绝用户

排队：给一个缓冲，MQ，需要建立长连接给用户响应

应用场景：

实际工作中，请求达到阈值之后，会将请求放到消息队列中，但是需要配合业务进行修改，不能是同步的返回

请求到达服务端，服务端马上给一个响应，如果加上排队的功能，服务端给用户响应的就是排队中，排在第几位，这个时候可能还需要websocket或者netty实时给用户响应，现在排在第8位，第7位，第6位。如果让用户体验更好，那就可以做，如果想简单一点，也可以直接拒绝





##### 基于时间量之固定时间窗口



1s之内就接受1000个请求，但是如果第1s的最后接收1000个请求，第2s的开始接收1000个请求，也就是第1s的末尾和第2s的开始间接的组成了中间的1s，而中间的1s也算是系统的1s，这时候就相当于1s内处理2000个请求，会发生请求突刺，那么系统就会崩溃

![image-20230309112600367](%E5%BA%94%E7%94%A8%E4%BF%9D%E6%8A%A4.assets/image-20230309112600367.png)

##### 基于时间量之滑动时间窗口



###### 请求突刺

![image-20230309113718147](%E5%BA%94%E7%94%A8%E4%BF%9D%E6%8A%A4.assets/image-20230309113718147.png)

##### 漏桶算法

漏桶算法：采用恒定的时间间隔，向服务释放请求，避免了服务的波动

![image-20230309140257873](%E5%BA%94%E7%94%A8%E4%BF%9D%E6%8A%A4.assets/image-20230309140257873.png)

漏桶算法的极限：漏桶的队列长度就是漏桶算法的极限，如果队列满了，那只能拒绝

实现：存储的队列，当外部请求来时，先将请求放到队列中，以一定的频率把请求释放给服务

![image-20230309113957382](%E5%BA%94%E7%94%A8%E4%BF%9D%E6%8A%A4.assets/image-20230309113957382.png)



漏桶算法的缺点：

1.服务无法及时处理完请求，漏桶里有请求等着处理，从而造成请求的阻塞，也会有系统性能的下降

服务处理的太快，但是漏桶里的请求处理的太慢，也会有系统性能的下降

![image-20230309115420552](%E5%BA%94%E7%94%A8%E4%BF%9D%E6%8A%A4.assets/image-20230309115420552.png)

2.浪费

漏桶里的队列长度因为不能够容纳超过自身长度的请求而拒绝，此时就会出现浪费的请求

针对需求做优化，解决瞬间的突刺，就出现了令牌桶算法

##### 令牌桶算法

用户请求时，如果能够从桶中拿到令牌，就可以请求服务，如果拿不到令牌，就不能请求服务

![image-20230309140055432](%E5%BA%94%E7%94%A8%E4%BF%9D%E6%8A%A4.assets/image-20230309140055432.png)



漏桶算法和令牌桶算法

令牌桶算法：固定的速率往桶中加令牌，请求是否被处理需要看桶中是否有足够令牌，如果足够就能够处理请求，如果桶中令牌没有了，就不能处理请求，直接拒绝。

令牌桶算法限制的是：恒定的流入速率，允许一定的请求突刺，只要桶中的令牌足够，那么请求突刺是能够解决掉的

如果再将请求获取的令牌还给令牌桶，会出现请求突刺的问题，

漏桶算法：按照固定的速率去处理请求

漏桶算法限制的是：恒定的流出速率，将一定的流入速率做一个缓冲





#### 从系统内部的角度：基于资源的限流

资源不够用了，内存快满了，CPU快满了，磁盘也快满了

找到系统内部影响性能的关键资源

连接数：系统只有100个连接，第101个用户来拿连接，肯定拿不到，资源不够，把用户限流，让用户别来了

线程数：类似

请求队列：类似

CPU参数：Perl，读系统的CPU参数和内存参数来进行限流控制





基于资源的限流比较基于请求的限流，更能反映当前系统的压力，这对系统的压力是一个更直接的反馈

##### 基于资源的限流的难点

1.确定关键资源，确定关键资源的阈值，通常是一个逐步调优的过程，自己先预估，进行压测验证上线观察之后调优

连接数的限制：可以使用池化的技术，从池中获取，获取不到就进行限制

Tomcat中的connectior标签：很多的配置，都能实现连接数的限流



池化技术：线程池，连接数

队列大小：请求队列

CPU参数：独立的系统去做，读系统的CPU使用率和内存使用率来进行限流控制



举例：

Tomcat

```html
<connectior>
	<acceptCount></acceptCount><!-- 如果Tomcat线程池满了，再进入的连接会进入阻塞队列，如果超出排队的容量，就直接拒绝 -->
  <maxConnection></maxConnection><!-- 最大连接数，如果超过最大连接数，那么就去队列等着 -->
  <maxThread></maxThread><!-- 用来处理请求的最大线程，如果请求的处理量大于最大连接数，那么系统也会假死 -->
</connectior>
```



### guava之限流RateLimiter







如果有好几个调用方，调用同一个提供方，每个调用方给多少的并发，是不是需要综合考虑

可以考虑令牌桶算法



## 节流

去抖，限制流量的一种手段

举例：

https://www.zhuayuya.com/ 搜索输入框，每输入一个字就会请求一次，前一个字的请求很快会被后一个字的请求覆盖掉

如何减少网络的请求？

举例：

定义一个时间窗口，在1s内输入的字是开源，只接收某个时间窗口的最后一个请求，比如：1s内输入的是开源，只请求开源，开字没有请求



## 隔离

将系统或者资源分开，系统有故障，要把故障限定在可控的范围之内



### 隔离的手段



#### 数据隔离

数据隔离：分清楚数据从重要性上进行排序，也就是数据重要性排序

非常重要，次重要的，不重要的

如果业务量很大，是需要做一些物理隔离的。一旦数据做了物理隔离，对应着业务也要进行拆分，类似于分库



#### 机器隔离

机器隔离：对同一个服务会有很多的调用者，调用者也是分等级的

可以为重要的调用者单独配置服务器，不要让不重要的用户影响重要用户的一些调用

举例：

阿里云的A，B，C类用户，对不同用户的服务是不一样的，对不同用户的保证也是不一样的，通过什么进行保证，就是隔离

可以通过用户的标识去路由



#### 线程池隔离

线程池隔离：通过分配线程池

线程池隔离需要消耗额外的线程，需要做额外的切换

将请求分类，将不同的请求交给不同的线程去处理，当一个 业务出现故障，不会将故障扩散到其它的线程池，从而保证其它线程的可用性。hystrix

举例：

Tomcat，500个线程，同时可以处理500个请求，Tomcat调用很多的服务，在这500个线程里面，调用了A，B，C，如果此时线程调用A等了很久，那么调用A的这个线程就卡在自己的服务器里，后面的请求也会跟着卡，这样 因为A的卡顿会导致其它线程的阻塞

解决方案：

将调用A的线程隔离起来，就给A10个线程，最多这10个线程废了，剩余可用的线程数500 - 10 = 490个

#### 信号量隔离

信号量隔离：计数器

举例：

在访问资源之前，先获取信号量里面有没有值，如果有，就能访问，访问之后将值释放给信号量，后面就能用了

一旦达到阈值，线程获取不到信号量，那就丢弃请求，而不是阻塞的等待

类似于商家 店铺人已经满了，在店外摆了一些凳子，如果有人来了就占用凳子，如果人走了凳子留下来，如果店外的凳子都满了，那么如果还有人来，只能拒绝



#### 集群隔离

将服务分组，单独分成一组给核心业务

举例：

秒杀系统：商品模块、订单模块

当秒杀来的时候，这几个模块的压力是很大的，这几个模块可能扛不住，这几个模块需要的 资源还很多，其它模块的资源就要让给这几个模块，这几个模块抱成团放在一起。比如：部署到一个高网速，高配置的机房，这几个模块是一个整体的，打包的服务，是独立隔离的，跟其他不重要的模块是隔离开的

实现：

注册中心，给指定服务打上分组的标签



#### 机房隔离

系统中有3个服务，这3个服务彼此之间有调用，部署的时候，将这3个 服务部署到两个机房当中，也就是每个机房中都有这3个服务，在同一个机房当中，服务只能调用本机房的服务，机房内的服务是可以彼此调用的，机房外的服务是不可以彼此调用的

举例：

云厂商的可用区

实现：

可以通过局域网的IP地址来做限制

可以通过路由，路由到指定机房的服务里面



#### 读写隔离

主从，

写操作：create、update、delete去主库写，select读操作去从库读

#### 动静隔离

把动态数据和静态数据识别，然后分开，静态数据放到静态服务器上，动态数据放到缓存/数据库里

读静态数据和读动态数据访问的服务器是不一样的

实现：

静态数据可以放在：Nginx，Apache

动态数据可以放在：Redis，MySQL



#### 爬虫隔离

热门网站的爬虫流量和正常的流量是5：1，平时5个爬虫，1个正常用户

但是有些系统，爬虫的访问量太大而导致服务不可用



实现：

限流

将爬虫和正常的请求分开，可以通过

识别同一个ip频繁的操作，或者使用openrestry user agent对ip的访问进行统计



#### 冷热隔离

预见的热点数据或者服务提前隔离开

常规热点：

秒杀，抢购，提前知道这些数据或者服务，就需要隔离开



读可以利用缓存和数据库，可以将热点数据放到缓存

写可以利用缓存 + 队列，延迟去写



业务比较大，并且隔离的收益大于付出，就进行隔离



## 恢复

撤出限流，消除降级，关闭熔断



直接恢复系统并不是一个较好的策略



半开关：也是一种恢复 

第一，测试系统是否正常

第二，防止系统启动后，缓存是空的，那么查询就又会去数据库，请求如果非常大，系统性能又是下降的

访问量是要逐步增加的，吞吐量有一个爬升的过程。类似于缓存预热的过程

系统预热的原因：

第一，Java类实例的创建，反射的调用和通过反射调用创建实例，在系统启动初期，有许多类或者对象首次使用被加载的过程，这个过程会消耗系统的资源，也会带来用户平均响应时间的延长，系统的吞吐量自然是很低的

第二，缓存数据的预热，系统刚启动时，缓存中什么都没有，需要去数据库查询，数据库查完之后再写入到缓存里，然后再给用户响应，后面的请求才能在缓存中查询到数据



预热类似于灰度发布，如果恢复系统，那么先放进一小部分请求去试一下，去激活系统，该加载的加载，该预热的预热，后面再放进大量的请求

通过限流逐步提升阈值，系统刚启动时，先限流10个，然后20个，接着1000个，可以通过时间窗口去改变限流的阈值



限流可以单独的一个时间窗口一个时间窗口开放

也可以根据系统用户的标签来限制，比如：18岁以下的用户有10个，18岁以上的10000个，系统只让18岁以下的人来，这样就达到了限流的目的



微信：

微信每个用户的推送不是同时的

微信上线新功能，不让主流用户去实验，让老人去实验



## 异地多活

小公司不用，大公司才用

系统扛不住高流量的时候，系统应该怎么办

不同地方部署服务的目的，解决部分服务出现故障，如何让系统继续提供服务，类似于负载均衡



如果只在一个地方存储，机房断电，火灾地震，导致系统瘫痪了，即使有备份，那么 将备份的业务恢复到正常能够提供服务的这种状态，花费的时间也很长

避免这种情况，就需要异地多活这套方案，部分服务出现故障，其它系统继续提供服务



### 异地





### 多活（不是备份）

多活是对外提供服务的，不是备份

备份的意义：防止数据丢失，便于数据恢复，多一份保障



### 异地多活需要满足的标准

1.正常情况下，无论访问那个节点都能得到正确的响应

举例：

访问北京和访问广州都可以

2.某地的系统在异常情况下，其它地方的系统也能够得到正常的响应

举例：

如果广州挂了，访问北京也是可以的



### 异地多活的分类

同城异区：一个城市部署两个机房，郑州的金水区和中原区

优点：同城的两个机房距离比较近，搭建高速网络，实现像一个机房的一样的网络传输速度，意味着，虽然是两个不同地理位置的机房，但逻辑上可以把它们看作一个机房，这样降低了系统复杂度，减少了成本

缺点：如果两个地区发生地震，两个机房都挂了，地震少见；如果两个地区发生停电

同城异区是应对机房级别的故障最优的架构



跨城异地：一般不在附近的城市找，北京和广州

缺点：

1.量变引起质变，有距离有速度就会有时间，有时间就会有延迟

北京到广州的RTT（Round Trip Time来回的时间）50ms

北京到上海的RTT（Round Trip Time来回的时间）30ms

2.中间不好控制，如果光缆被挖断了

这两种情况都会导致**数据不一致的问题**，数据不一致，业务也会有异常

举例：

系统中卡里有10000元，并且系统在北京和广州都部署了系统，我现在在广州，肯定 访问的是广州的系统，现在给别人转10000元，对余额的增减是在广州的机房完成的，我在广州的系统没钱了，但是广州到北京的光缆被挖断了，数据没有从广州同步到北京，我坐着飞机从广州飞到了北京，达到北京一看卡里还有10000元，我又给别人转了10000元，这时候就出现了数据不一致的问题



跨国异地：业务部署到不同的国家，会导致隔离，国内的账号登录不了国外的网站

相比较于跨城异地，距离更远，延迟更大，访问国外的网站GitHub

跨国异地的延迟已经无法支撑系统的正常运转，提供正常服务



举例：

为不同国家提供服务

谷歌搜索，中国和美国差几秒无所谓







负载均衡 -- 同城异区和跨城异地，通过DNS或者CDN，分流的思想

数据不一致的问题 -- 

角度：

**1.保证核心业务多活**

用户系统：注册、登录、修改用户信息，为了 支持海量用户，设计了异地架构，用户属于北京和广州

注册和登录场景：广州注册用户，此时用户数据还没有同步到北京，这时候，广州机房挂了，系统支持异地多活，广州的用户就需要通过北京的机房去登录，结果用户登录 时发现北京的机房还没有该用户的信息

修改用户信息场景（根据时间进行合并）：广州修改用户信息，结果数据没有同步到北京，用户去北京访问，还是旧数据，用户再修改一遍，这时候广州改了，北京也改了，可能改的是一致的，那么合并数据会有两条相同的，选择最后修改的一条数据就可以了

合并数据以谁的为准，那怎么知道谁前谁后呢？如何知道广州和北京两个机房的时间是一致的？

解决方案：分布式id

在广州修改的，打一个版本号，版本号id是1

在北京修改的，版本号是2，

合并数据的时候以2为标准，这时候就使用到了分布式id



用户系统中，登录最重要，是核心业务

举例：

有1000万个用户，每天注册的人数几万，修改用户信息的人数几千，但是可能这1000万用户都需要登录

注册和修改用户信息都不是核心业务，异地多活影响不大，注册和修改用户信息都失败就重试

异地多活本来就保证了登录，登录是基于已有的数据做登录，是读操作



**2.保证核心数据的最终一致性**

异地多活是通过异地的数据冗余来保证在极端的情况下，业务数据也能够正常提供给用户

因此数据同步是异地架构设计的核心

只保证核心数据的同步就可以

举例：

异地多活的距离是固定的，时间是固定的，延时是固定的，所以只能

**尽量减少影响**

大公司或者国企自建网络，军网的线路是独有的，巨头公司：BAT购买专用的线路去传输，IDC机房

**尽量减少数据量的同步**

业务数据很复杂，全部同步代价太大，只同步核心业务的数据

举例：

session数据/token数据，有必要同步吗？没有，数据量太大，同步不值得，虽然影响用户体验，但是无伤大雅，用户在登录一次即可

**保证最终一致性，不保证实时一致性**

允许中间某个时段是不同步的



数据同步的手段

中间件的主从复制：Redis，MySQL

消息队列：MQ订阅发布

二次读取：用户在北京查不到，将该请求指向到广州，再次查询

回源读取：用户在A系统登录，A服务生成session，用户访问B系统，这时候从用户传递过来的sessionid，B系统对sessionid，发现是A系统生成的sessionid，就让用户去A系统 校验session。session信息没有从A同步到B，但是通过技术手段让请求从哪里来回哪里去，这就叫回源

重新生成：session，cookie，没了就没了，重新生成



*保证大部分用户的异地多活*

 微信支付宝都挂过，让一小部分用户忍着，大部分用户能用



### 异地多活的设计步骤



#### 业务分级

微信：聊天和朋友圈

技术给业务赋能

聊天是核心业务，但是微信的朋友圈肯定做了同步，因为在用户的角度没有影响，但是在公司的角度，广告收入可以赚钱

新闻网站肯定也做了异地多活，对用户没有影响，对公司也会有广告收入



#### 数据分类

对核心业务相关的数据进一步分析，识别出所有数据的特征



分类的维度

唯一性：数据是否要保证唯一，要唯一就需要同步，session要求唯一

举例：用户在广州注册的手机号，如果该手机号不同步到北京，那么也不允许在北京注册相同的手机号

需要通过中间的手段去保证，用户信息在MySQL中，没有同步到北京，那么信息也要在其它地方在存一分，让北京能够查到用户在这边已经注册过了，需要**额外的存储**能够支持北京来查询



实时性：

银行的账号余额



可丢失性：数据能不能丢失，session，cookie，重新登录



可恢复性：数据是否可恢复，session，重新登录



#### 数据同步

中间件的主从复制：Redis，MySQL

消息队列：MQ订阅发布

二次读取：用户在北京查不到，将该请求指向到广州，再次查询

回源读取：用户在A系统登录，A服务生成session，用户访问B系统，这时候从用户传递过来的sessionid，B系统对sessionid，发现是A系统生成的sessionid，就让用户去A系统 校验session。session信息没有从A同步到B，但是通过技术手段让请求从哪里来回哪里去，这就叫回源

重新生成：session，cookie，没了就没了，重新生成



#### 异常处理



数据同步延迟，数据丢失，数据不一致

多通道同步：MySQL的主从复制（电信） + 消息队列（联通），这两个操作走不同的网络

同步和访问结合：

北京和广州两个中心

A用户在广州登录，广州服务器有个session，A用户有个sessionid（带有广州标识的sessionid，比如sessionid以1结尾），同时session不同步给北京，A用户访问北京服务器需要带上参数：sessionid（带有广州标识的sessionid，比如sessionid以1结尾），北京根据sessionid计算判断是否是广州的，如果是广州的，那么北京将广州的session拿过来，这就是同步和访问结合

```
if(endWith(1)) {
	String session = HttpServletRequest.getSession();
	session.set(k,v);
}
```





