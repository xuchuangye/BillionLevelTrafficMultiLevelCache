# 数据库设计



## 数据库优化的理由

开发环境中，关系型数据库是各种业务系统中比较关键核心的一个存储系统

用户量和数据量的发展远远超过数据库厂商优化的速度

**收益方**：阿姆达尔定理，数值的计算，内存的读写，数据库的操作是频繁的硬盘IO的操作，耗时比较久，因此数据库读写的时间往往在系统的总响应时间中占比较高，所以优化数据库的操作，能够给系统的总响应时间带来ms，甚至是s级的降低

**数据库单点压力**：为了实现数据同步和数据的共享，数据库经常被设计为单节点，服务的集群，服务做了水平化扩张，但是为了所有数据每一个服务都可以共享到，好多公司就将数据库设计为单点系统，因为这个数据库的性能有大量的提升之后，那么各个节点也会都跟随着提升

**积累压力**：数据库随着运行时间的延长，数据库存储的数据量会增多，而数据量的增多会导致查询效率低下，读写效率的低下，最终出现性能的问题



## 数据库设计的优化



1.先设计数据库表的设计，再推导出使用对象，先根据需求设计数据库的关系模型，再根据关系模型确定对象和对象之间的关系

2.先确定对象和对象之间的关系，再将该关系转换成数据库表的结构

如果数据库的设计跟业务有冲突，设计比较别扭的时候不要怪自己，多跟产品经理沟通，是否是业务方面设计的不合理，尤其是业务涉及到状态变化的时候，不建议产品状态变化之间是多种多样，只能从一个状态变化到另一个状态

举例：

假设状态2表示取消操作

1 - 21中的21表示用户取消操作，3 - 22中的22表示商家取消操作

方便查询



同一个需求，同一组对象，不同的设计人员设计出不同的关系型数据库结构，

设计时有不同的意见时，不用去抵触，只需要考虑以下问题：

1.数据冗余：是否有数据冗余，尽量减少一份数据在多个数据库表当中存储，导致该数据维护非常麻烦。

根据业务进行分析，如果从查询的角度，不想跨表查询，那也只能多写一份。

如果写的少，读的多，数据冗余就冗余了，让读的效率高一些

2.数据不一致：在数据冗余的时候，一部分数据更新，而另一部分没有更新，就会出现数据不一致的问题

举例：

进入到新公司，接触到新项目，可能这个项目别人做了很久你去维护的时候，一定要注意数据不一致的问题，某个代码块改了这张表的时候多看看，是否有发消息的动作，是否有调用额外的二方库的jar包的方法的操作，可能这个操作或许会有对别的数据表的操作。如果修改之后导致数据不一致的现象，需要注意

3.插入异常：

A和B两条数据，B依赖于A，没有A就插入不了B，数据库设计的时候尽量独立，我不依赖你，你不依赖我

如果微服务多一些，可能这些问题遇到的会比较少，微服务大部分情况下都是单表查询

4.删除异常：

你把你觉得该删除的删除了，但是有一些数据该你删除了而没有删除，这些都是数据冗余带来的额外的影响







数据库的范式

等级越高，越严格，越能避免一些问题



第一范式：每个字段都是原子性的，不能 再进行拆分

反例：

设计字段喜欢使用json串，把json存储到字段里，或者字段里存储数组

可以思考一下，**是不是设计有问题**，是不是这些数据可以单独出去做成一张表，有80%可能是设计有问题，如果说各种问题都排除掉了，都没有问题，那么这种情况下，换一种**存储中间件**，比如说：使用文档数据库去存储，存储字段值不固定的数据



第二范式：表必须有主键（可以是一个，也可以是多个字段），非主属性必须依赖于主键，不能部分依赖主键

反例：

有一张好友关注表：主键是：关注人id，被关注人id，非主属性：关注人头像

该表设计不合理，非主属性只依赖于关注人id，没有依赖于被关注人id，这叫部分依赖主键，所以非主属性：关注人头像应该设计到关注人信息表当中



第三范式：没有传递依赖，非主属性必须直接依赖于主键，而不能间接依赖于主键

反例：

有一张员工表，主键：员工id，非主属性：部门id，部门名称，部门简介

部分名称和部分简介这两个属性直接依赖于部门id，而不是直接依赖于主键：员工id，所以这两个属性不应该设计到这张表中



反范式：

建议在范式的基础上进行修正，目的是为了减少范式所带来的负面影响，不是彻底的逃避范式

为了对业务性能的提升，对开发使用的方便，会违反一些范式的规定、设计的方案，这种情况比比皆是



遵守范式还是反范式，要根据业务情况

如果系统是比较重业务的系统，对性能和开发的要求不高，最好是遵守范式

如果系统对某些查询较频繁，可以考虑数据冗余，也就是反范式



## 巨量数据的优化

一张数据表在刚刚创建的时候响应时间是满足要求的，但是随着时间的推移，表中数据越来越多，响应时间越来越长，随着数据的增多，数据文件和索引文件都会变大，从而使得增删改查操作需要的工作量增加，最终数据库响应时间的增加

数据量的增加 -> 响应时间的增加 

因此必须在数据库的数据量达到 瓶颈时，进行优化工作，提升读写性能

常用的方法：需要查询的字段上建立索引，MySQL性能调优



实现难度和影响的范围越来越大，优化主流的步骤：

表分区 -> 分库分表 -> 读写分离



### 表分区

表是一个逻辑概念，代表结构相同 的数据，在数据库里，每一张表对应磁盘上存储的一个ibd的文件，data目录/数据库名

![image-20230308095101799](%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1.assets/image-20230308095101799.png)

表分区是基于并发和并行的思想，对数据表的读写操作进行分流

分流：对一个ibd文件的请求，分发到对多个ibd文件的请求

将一张表根据指定的条件水平切分，将数据的多个物理表进行存储，逻辑上还是一张表

优点：

1.当查询条件可以判定某个数据在某张分区表的时候，知道在哪一个分区上，只需要在这个分区上进行查询，而不需要整张表的扫描

2.表分区之后，对外还是一张逻辑表，意味着业务的代码不需要因为数据表的分区而作任何修改

3.将不同的分区文件存储在不同的磁盘上，从而将读写分散，充分利用磁盘的读写性能，还可以对分区进行单独管理。比如：备份和恢复，备份和恢复某一个分区的所有数据的时候，不影响其它区。当遇到数据量比较大，遇到数据量瓶颈的时候，对数据量较大的表进行分区，是一个 非常不错的选择

缺点：

每个表都需要加partitiion关键字

跨分区查询性能也很低

如果做表连接跨区了，那么性能也很低



#### 分区的常见类型

range范围分区：

对给定的数据按照区间进行分区

基于属于一个给定连续区间的列值，把多行分配给分区

举例：

对某个字段：0 ~ 10， 11 ~ 20

```mysql
create table emp(
	`no` varchar(20) not null,
	`name` varchar(20),
	deptno int,
	birthdate date,
	salary int
)

partition by range(salary)(
	partition p1 values less than(1000),
	partition p2 values less than(5000),
	partition p3 values less than(10000)
);
#salary：1 ~ 1000范围在p1分区，1001 ~ 5000范围在p2分区，5001 ~ 10000范围在p3分区

insert into emp values('001','shineyork',10,'2021-10-10',5000);
insert into emp values('002','keke',20,'2021-10-10',1500);
insert into emp values('003','coco',10,'2021-10-10',9000);
insert into emp values('004','xiaoming',20,'2021-10-10',1000);
insert into emp values('005','zhangsan',30,'2021-10-10',6000);
```



list列表分区：

跟range类似，range是范围，list是枚举的具体值

类似于按 range 分区，区别在于 list 分区是基于列值匹配一个离散值集合中的某个值来进行选择。

```mysql
create table emp(
	`no` varchar(20) not null,
	`name` varchar(20),
	deptno int,
	birthdate date,
	salary int
)

partition by list(deptno)(
	partition p1 values in (10,20,30),
	partition p2 values in (1,2,3),
	partition p3 values in (4,40)
);
#deptno：10、20、30在p1分区，1、2、3在p2分区，4、40在p3分区

insert into emp values('001','shineyork',1,'2021-10-10',5000);
insert into emp values('002','keke',20,'2021-10-10',1500);
insert into emp values('003','coco',10,'2021-10-10',9000);
insert into emp values('004','xiaoming',40,'2021-10-10',1000);
insert into emp values('005','zhangsan',2,'2021-10-10',6000);
```



hash散列分区：

给指定的属性进行散列函数

基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含 MySQL 中有效的、产生非负整数值的任何表达式

```mysql

drop table if exists staff;
create table staff(
  id int not null,
  fname varchar(30),
  lname varchar(30),
  hired date not null default '1970-01-01',
  separated date not null default '9999-12-31',
  job_code int not null default 0,
  store_id int not null default 0
)
partition by hash(store_id)
```

key分区：

类似于按 hash 分区，区别在于 key 分区只支持计算一列或多列。且 MySQL 服务器提供其自身的哈希函数。必须有一列或多列包含整数值。

```mysql
create table emp(
	`no` varchar(20) not null,
	`name` varchar(20),
	deptno int,
	birthdate date,
	salary int
)

partition by key(year(birthdate)) partitions 4;
```



#### 分区的注意事项

1.做表分区时，要结合查询规则，尽量保证常用查询落在一个分区中

举例：

有一张大数据量的表：表中字段：学生姓名，老师姓名

如果查询经常是按照学生姓名作为条件去查询老师姓名的，那么最好是按照学生姓名为依据进行分区，当输入某个学生姓名查询时，相关的操作会 分流到该学生姓名所在的分区，避免了数据库查询多个分区再合并的开销

2.在查询某个已经分区表的时候，尽量将分区条件放到where语句当中

举例：

如果查询经常是按照学生姓名作为条件去查询老师姓名的，并且已经 按照学生姓名进行了表分区，那么最好将学生姓名作为where的查询条件



表分区提升系统的性能：

在日志系统当中，可以将久远的数据分到单独的区上，不影响热点数据的访问

在人员管理系统中，可以根据人员所属的机构进行分区，在同一个机构操作这些人员

对表进行分区，能够在不影响业务的条件下，提升数据库的 并发性能

缺点：

表分区之后，如果出现跨区查询，反而适得其反



### 分库分表



目的：

1.**从业务的角度**：

通过业务进行拆分，把大的复杂的系统拆分成 多个业务子系统，之间通过中间件 进行通信

优点：便于团队的分工协作，也便于未来对某个系统进行扩张

2.**通过分库分表应对高并发**，需要看场景：读多写少，可以从库去读，加缓存；读少写多，写的QPS达到系统的瓶颈，就需要考虑分库分表

3.**数据隔离**：将核心业务和非核心业务进行拆分，在设计系统的时候，不要将数据同等对待，一旦因为 非核心业务导致数据库宕机，那么核心业务也会受到牵连，分开 之后，对系统的安全是有保证的



#### 分库分表的设计



分库：分库是将一个数据库的数据拆分到多个数据库中

分表的方式：

1.不破坏表结构（表结构外部）

举例：

一个数据库有两张表：a表和b表，a表拆分到一个数据库中，b表拆分到一个数据库中

优点：

假设一个数据库中有两张表a表和b表，如果a表的数据急剧增大，那么b表的操作也会受影响，让a表的性能给拖垮了，这个时候不破坏表结构的拆分是最好的

2.破坏表结构（表结构内部），垂直分和水平分



垂直分：

字段1，字段2，字段3，字段4

拆分之后，数据条目数不变，数据的字段变少



水平分：

字段1，字段2，字段3，字段4

第1行数据

第2行数据

第3行数据

第4行数据

拆分之后，数据条目数变少，数据的字段数不变



场景1：用户需要查询表中的所有信息，经常需要查询字段1，字段2，字段3，字段4这几个字段，但是这张表的数据变大了，需要进行拆分，那么肯定是水平拆分

场景2：婚恋网站，用户查询频率最高的只有年龄和性别这两个字段，对名称，昵称，个人介绍这些字段都不看，但是这张表的数据变大了，需要进行拆分，那么肯定是垂直拆分

场景3：按照日期进行拆分，那么 肯定是水平拆分

注意事项：

分库分表会多出一些额外的操作：

-   路由操作：需要业务逻辑将原本指向一个数据库表的读写请求分散到拆分出来的一个或者多个表上
-   拼接的操作：根据业务逻辑将表拆分后放到多个数据表里，数据都分片了，如果想要得到完整的数据，那么需要一个一个都拼接起来

开发中遇到问题：先使用 简单方法 解决 ，解决不了，再复杂



#### 分库分表的方法

场景：一张表有1000万条数据，分到多个数据库表里



##### 范围路由

范围路由：**选取一个有序的数据列**作为条件，按照一定的范围区划分，属于不同段的数据被分散到不同的数据库当中

1 ~ 100一个数据库，101 ~ 200一个数据库，以此类推

考虑：分段大小的选取，分段太小会导致切分后的子表数过多，增加维护难度；分段太大有可能会存在单表数据量过多的性能问题

分表的依据：分表之前，表的字段多少以及每条数据的大小，分表之后，表的各方面性能能否满足系统要求

**优点**：可以平滑的扩充新表，只需要增加子表的数据量就可以，原油的数据不用动

举例：

1 - 100， 101 - 200，201 - 300，数据量增加，表可以无限制的扩充下去，只需要增加子表的数据量就可以，原油的数据不用动



缺点：数据分布的不均匀，会导致子表之间数据量的不一致，可能会导致某一些表还有问题

举例：

1亿个数据，分成两张表，第一张表8000万个数据，第二张表只有2000万个数据



##### hash路由

hash路由：选取某个列或者一部分列，进行hash运算

举例：

有100个用户，规划了10个数据库，可以通过取模10作为hash运算，然后让用户分散到对应的数据库中

优点：数据分布的均匀

缺点：

-   扩充新表很麻烦，所有的数据（包括原有的数据）需要重新分布

    原来10个数据库，11号用户进行hash运算11%10=1，11号用户落在1号数据库中

    现在新增一个数据库，11号用户进行hash运算11%11=0，11用户在1号数据库的数据需要全部转移到0号数据库中，非常的麻烦

-   初始表的数量的选择是个问题，表的数量太多，维护比较难，表的数量太少，也会导致单表数据量过多存在性能问题



#### 分库分表的问题



##### 分布式id的问题

在分库之前，使用的是自增id，有100万条数据，id从1到100万，如果分成两张表，每个表的id都是自增的，id在整体的全局的还能唯一标识一条数据吗？这时候id=1能够表示两条数据，此时就需要全局id生成服务

注意事项：

1.全局唯一，必须保证id是整个系统里面全局唯一的

关键信息：时间戳（某时某刻某分某秒某毫秒）、机器号（1号机器）、序列号（在这个时刻在这个机器上能够生成多少个，1s生成10000个）

2.高性能，必须是高可用、低延迟的id生成

id生成必须要快，id生成尽量使用位运算，否则生成id反而会成为业务的瓶颈

3.易使用，好接入和调用



4.要么递增，要么无序（根据业务需求）



分布式id的具体生成方式：

-   uuid
-   数据库自增id，独立数据库满足整个系统id的不重复
-   号段，
-   Redis自增：通过Redis获取id，将id放到数据库中，通过id去标识唯一的记录，并不是把id放到Redis，
-   雪花算法
-   滴滴的TinyID
-   百度的UIDGenerator
-   美团的leaf



##### 拆分维度的问题

电商系统-订单表：用户id，订单id，商品id，等等，查询字段就这三个是常用的

拆分的维度一定要结合业务的场景，我的场景用哪个字段多一些，我就拿什么去查

拆分维度的依据：根据自己业务的情况，看哪个字段用的多



问题：面试遇到的问题，关于我已经写了一个id的生成规则，百万并发量，并且无重复，面试官问为什么不采用Redis？

1.我自己写的就可以满足产品的性能要求，我不需要引入一个Redis组件

2.多一个组件多承担一些风险

问题：当面试官问你为什么不用什么什么？

一定要想：

1.我做的解决方案满足当时公司业务的需求

2.我额外付出的什么和我得到的什么给面试官说清楚

3.面对面试官的挑战，不要慌，按照自己的逻辑走



电商系统-订单表：用户id，订单id，商品id，等等，查询字段就这三个是常用的

之前是查询用户比较多，所以根据用户的维度进行拆分

现在是查询订单比较多，但是因为是根据用户id进行拆分的，所以通过订单id查询效率非常低，如何解决？



解决方案：

1.理想方案：重新按照订单的维度进行拆分，但是代价非常大

2.过渡方案：建立索引表，或者说是映射表，建立用户id和订单id的对应关系表，根据订单id查询出用户id，再根据用户id查询需要的数据

映射表不一定放到数据库，也可以放到Redis

3.阿里的dts，datax，都可以做增量同步



##### join的问题

商品、订单、用户，这三个表在一个数据库中，通过join就能查询

查购买化妆品 的用户 当中的女性用户 的列表

分库之后，如果这三张表在不同的数据库中，join不到了



1.不让在数据库层面做join，**在代码层面做join**，降低数据库发生慢查询的概率

2.把数据库的数据导入ES进行查询，从而解决数据库层面的问题

3.目前的趋势：数据库越简单越好，阿里规约：禁止三张表做关联，禁止使用存储过程，禁止触发器，现在连两张表做关联都不让了



##### 事务的问题

分布式事务，MySQL的XA的jar包，查询两个库，汇总到一个地方，做两阶段的提交，但是不好用

shardingsphere



##### 成本问题

人民币的成本

维护的成本

非必要不分库，能不分库就不分库，不要过度设计

现在满足 现有业务的情况，用越简单的方案实现越好，活在当下，不用有这个担心



**问题：多大数据量需要分库分表**

当数据的查询性能或者写入性能不满足业务的标准，就开始进行分库分表，不是看数据量

以系统实际的性能为标准，去衡量

举例：

就算有1亿条数据，但是查询性能10ms，那就没有必要分库分表

就算有100万条数据，但是查询性能1min，那就必须分库分表

假设我的一条数据是1G，当我数据量达到300万的时候已经来不及，所以我要结合当前的数据量来决定我什么时候进行分录分表



### 读写分离



1个数据库

2年后，10个数据库

4年后，又慢了

10个数据库每一个数据库都做读写分离（前提 -> 读写分离需要多个数据库支持）

读写分离采用的是分流的思想



读写分离的原因：

数据库的写锁对数据库的并发有影响



读写分离的理由：防止阻塞

X锁-写锁：只能一个人进行，读和写都会阻塞

S锁-读锁：读并发执行，写串行执行

此时就可以进行读写分离，保证不受到数据库锁对数据库的影响



读写分离的具体场景：读多写少

读写分离的不适用场景：读少写多



一个数据库 负责写，这个数据库叫主库

一个或者多个数据库负责读，这些数据库叫从库

一主多从





#### 读写分离的问题

路由问题：读操作去从库执行，写操作去主库执行

读操作select S锁，sql语句是select开头的使用拦截器指向到读库上，写操作create update delete add X锁，sql语句是这些开头的使用拦截器指向到写库上

主从复制的问题：

1.写主库如何高效的同步到读从库

主库写了一遍create update delete add，从库又写了一遍create update delete add，失去了读写分离的意义

解决方案一（高并发，数据一致性）：

在主库里开启binlog功能，把binlog传给从库，从库把binlog写成relaylog，解析relaylog，最后重现数据

解决方案二（高并发，不在乎短暂的数据不一致）

base方案，为了应对的高并发，保持系统的高可用，先将数据接收下来，先给用户或者调用方一个响应，然后再慢慢同步

要么牺牲可用性，要么牺牲一致性，而要两者都能够保证，那么就必须容忍中间短暂的数据不一致



2.主库同步到从库，有一个时间差的问题



业务场景一：用户 注册（主库），登录（从库）

用户注册完之后，主库会将用户数据同步到从库，但是会有一个时间差，此时用户马上进行登录时会发现没有该用户信息，对用户的体验非常不好

解决方案一：

可以将用户注册之后的第一次查询，指到主库，如何知道用户是否是第一次查询？

用户注册完，根据身边标识 + 手机号 生成Redis的key，手机验证码作为value，存储到Redis，判断Redis中是否有这个key，如果有就是第一次

该解决方案的缺点：

和业务耦合比较大

解决方案二（个别业务用）：

先去从库查询，如果没有，再去主库查询，如果没有，那就真的没有了



业务场景二：

主业务用主库，非主业务用从库

用户管理系统，用户的注册和登录都走主库，用户的名称、头像等走从库

微信的用户头像更新也比较慢，博客网站修改个人信息，中间有一段时间访问不到



### 实现

分库分表，读写分离。 

读写分离：将读和写，分开。 

分库分表：将 数据 分库。

分

分配机制：将不同的sql 分发到不同的机器上。 

select ----某台机器上

update --某台机器上。 

where id = 1 某台机器上

where id = 2 某台机器上。 

拦截，判断，分发。

### 方法

代码封装：dao抽象一层。做个数据库表和Java中间的夹层。

参考：tddl(Taobao Distributed Data Layer) 头都大了。

Shardingjdbc。需要改代码。

中间件封装：mycat。