分流：减少每一个系统的处理的请求数



# 缓存设计



导流：将原来复杂的操作请求，引导到简单的请求上

举例：

一大堆查询的sql，并且只查询一个结果，那么查询的效率比较低



缓存：空间换时间的一种说法

将第一次查询的结果进行缓存，之后查询的效率就会非常高，提高系统的吞吐量，系统在单位时间内处理的请求更多

Redis，memcached，localcache，guava，客户端缓存

举例：

user_info：姓名，年龄，性别，xxx

如果每次查询，都需要：select * from user_info where id = xxx，

通过Redis缓存，可以直接getKey这种内存操作进行获取，减少硬盘的IO



问题：什么数据适合做缓存？

读多写少，能够给系统减少大量访问的



## 缓存的收益



采用技术方案时，一定要考虑的内容：成本和收益



成本：

写代码的时间

机器的配置

开发人员的学习成本



收益：





缓存的目的：读，写

缓存的位置：介于请求方和提供方之间

缓存的收益：节省了响应时间

缓存的成本：一个请求对应一个结果，kv

在缓存命中的情况下（命中率为P）：

计算key的时间

查询key的时间

转换值的时间

在缓存没有命中的情况下：

所有数据的查询时间 = 计算key的时间 + 查询key的时间 + 转换值的时间 + (1 - P) * 原始查询时间



```
计算key的时间 + 查询key的时间 + 转换值的时间 + (1 - P) * 原始查询时间  <<远远小于<<  所有数据的原始查询时间
```



通过公式可以看出：

-   将耗时特别长的查询放在缓存里
-   提高查询命中率
-   读多写少，缓存主要是为了方便查询，存储还是存数据库，所以写操作还会增加额外的消耗



## 缓存键的设计



为了安全，防止key的冲突

考虑计算（生成）key的时间

单向函数：给定输入，很容易、很快计算出结果，给定结果，很难计算出输入

算法的要求：正向快速，逆向困难，输入敏感，冲突避免

md4不安全，md5不安全，sha0不安全，sha1不安全

sha-256，10的77次方，冲突的概率极低，但是生成key值比较慢

sha-512，





考虑查询key的时间

查询key的速度：取决于：key存储的物理位置（内存，硬盘）



考虑转换值得时间

转换key值的方式：

-   序列化

    将对象写入缓存之前，先将对象进行序列化，最终缓存的是对象的序列化串，读取数据时，需要读到序列化串在进行反序列化操作，才能得到对象的本身

    缺点：序列化和反序列化会有额外的成本

-   对象

    不需要序列化和反序列化的处理，更为高效

    缺点：数据污染，两个请求同时读取缓存，其中一个请求读取到另一个请求正在修改的数据，那么这个时候就会出现数据污染

为了保证缓存数据的一致性，最好序列化处理

如果在业务中，不会对缓存的数据进行修改，那么最好对象，减少序列化和反序列化的成本



总结：

**缓存需要考虑的三个要素**：

1.key的冲突与无碰撞，key的高效生成

2.高效查询

3.高效转换

这三个要素都已经备中间件提供的API封装了



实际工作中：前缀 + 业务关键信息 或者 业务关键信息 + 后缀

最好是公司统一制定规范



user_order_xxx

user+order+xxx

user-order-xxx



## 缓存的更新机制（双写一致性）



缓存是调用方和数据提供方中间的暂存方

因为缓存数据来源于数据提供方，所以缓存的数据会随着数据提供方的数据，变化而变化



缓存的来源：

### 被动更新

1.你给我（被动更新），有效期到之后，再次写入

（1）客户端查询数据，如果缓存中没有，从数据提供方中获取，写入缓存（设置一个过期时间t）

（2）在过期时间t内，所有的查询，都由缓存提供。所有的写，直接写入数据库

（3）当缓存数据t到过期时间了，此时缓存中没有数据了，之后的查询，重新回到第（1）步

虽然第（2）步会出现脏数据，不能保证缓存数据和数据提供方的数据一致，但是实现简单，高效

应用场景：适合对数据准确性和实时性要求不高的场景。

举例：

商品的关注人数，商家店铺的关注数

### 主动更新

2.我去取（主动更新），被其他操作直接填充



主动更新从：

数据库的角度：写数据库

缓存的角度：更新缓存，删除缓存



思路：围绕着一个定量进行考虑，将所有的变量进行一一列举，才不会有异常的遗漏



#### 更新缓存，更新数据库

容易出现的问题：

先更新缓存，然后再更新数据库，如果数据库因为事务出现错误而进行回滚，那么就会导致缓存和数据库的数据不一致

结论：此方式数据不一致的风险比较高，所以一般不会采用



#### 更新数据库，更新缓存

容易出现的问题：

1.线程不安全的角度：请求被阻塞时，导致数据库的结果与实际缓存中的结果不一致

![image-20230306145626883](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230306145626883.png)

2.业务角度：数据库存储的值比较简单，但是缓存存储的却是修改数据库之后需要大量计算之后才能得到的值，非常消耗性能，并且如果该缓存没有被使用，那么更加浪费资源，所以这种情况下不值得更新缓存

结论：此方式非常消耗性能，并且线程不安全，所以也一般不会采用



#### 删除缓存，更新数据库



容易出现的问题：

读操作比写操作快，大概率会导致缓存的数据和更新之后数据库的数据不一致

![image-20230306102126666](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230306102126666.png)

解决方案：延时双删

休眠时间：根据项目读操作的业务逻辑耗时来进行判断，确保读数据请求结束之后，写请求可以删除读数据造成的脏数据

![image-20230306102233498](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230306102233498.png)



结论：因为读操作比写操作快，所以一般会出现缓存的数据和更新之后数据库的数据不一致，所以一般不会使用



另外一种应用场景：读写分离

读写分离也会造成数据不一致的情况，因为主库和从库的数据没有进行同步，因此解决方案还是延时双删

![image-20230306103328643](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230306103328643.png)



总结：

不管数据库有没有读写分离，为了解决缓存和数据库数据不一致的问题，都会出现两次删除，也就是写操作，那么必定会造成系统吞吐量的下降，解决方案：可以将第二步删除操作变成异步操作

![image-20230306105438200](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230306105438200.png)



**高德面试问题：延时双删都有哪些步骤？如果其中一个步骤失败了，如果进行处理？**

##### 延时双删的步骤：

-   第一次删除缓存，如果失败了，返回客户端删除缓存失败的响应，没有什么影响

-   更新数据库，如果失败了，事务回滚，也没有什么影响

-   第二次删除缓存，如果失败了：

    -   重试该操作

    -   小技巧：如果当前的操作无法进行回滚时，为了保证后续数据的一致性，（最节省成本的就是）硬着头皮往下走

        如果遇到重试的地方，可以使用中间件（消息队列）重新发消息

        如果删除缓存的key失败了，将删除key的消息放在消息队列中，订阅消息，接着删除该key，如果删除成功，给消息队列进行确认，消息队列以后就再也不发了，如果删除失败，消息会一次一次进行重发，总会删除掉的，就算删除不掉，将删除的key放到死信队列，给开发者发邮件，手动执行进行删除

    -   canal

    -   开启binlog，记录所有操作指令的日志，通过canal订阅binlog，通过指令进行删除操作，如果删除失败，再通过程序订阅消息队列，将第二次删除缓存的操作和业务代码进行解耦

    

#### 更新数据库，删除缓存（经常使用）

cache-aside模式：会将缓存作为辅助工具，即使缓存没有数据或者缓存崩溃了，调用方也可以通过数据提供方完成所有的读写操作



应用场景：

修改完页面，删除静态页面



前提：缓存中没有数据，数据库中有数据

A请求：查询数据，B请求：更新数据

A：查询数据，缓存中没有数据，查询数据库，获取旧值

B：更新数据库，数据库中是新值

B：删除缓存

A：查询完结果，需要将获取到的旧值写入缓存



出现问题：

缓存和数据库不一致，出现脏数据

出现问题的情况：

读操作比写操作慢，但是发生的概率极低

缓存无数据

解决方案：

如果非要解决，延时双删。





#### Read/Write Through（大型项目/并发量特别高）

在这个方案中，缓存成为不可或缺的，调用方只和缓存打交道

系统在刚启动的时候，会将数据库中初始化的数据放到缓存里，不能等系统启动完之后，再放到缓存里



![image-20230306144042455](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230306144042455.png)



#### Write Behind（大型项目/并发量特别高）

以缓存为主，最好将缓存持久化

![image-20230306144112620](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230306144112620.png)

优点：降低了写操作的时间，提高系统的吞吐量

缺点：如果缓存崩溃了，或者缓存中的数据丢失了，那么数据就永久消失了



## 缓存清理机制



如何提升缓存命中率：尽可能缓存更多的数据，所有的数据都存储到缓存，那么缓存的命中率100%



缓存清理机制的目的：

-   需要使用有限的缓存空间，尽可能的发挥缓存最大的作用

-   将没有用或者用的比较少的数据进行清理，将经常使用的或者高频访问的数据存储到缓存

缓存清理机制的策略：

-   读的时间频率：当准备清理一个数据的时候，发现该数据一直被访问，那就可以认为该数据马上会被访问

-   写入的时间点：当一个数据刚被写入到缓存时，那么接下来该数据很有可能被访问

问题：如何预测一个数据将来被访问的次数

读的时间频率：当准备清理一个数据的时候，发现该数据一直被访问，那就可以认为该数据马上会被访问

写入的时间点：当一个数据刚被写入缓存时，接下来很有可能被访问

代码实现：

```
1.肯定要根据公司的项目业务进行分析，设置一个阈值，多少次访问次数才算是频繁访问，多久才算是刚被写入的时间
2.创建一个变量，每访问一次记录一次，记录访问的时间
```







### 时效性清理机制

给缓存设置过期时间，到期缓存会自动清理

缓存中的每一个数据都有生存时间：ttl，过期时间。当到了过期时间时缓存就会被清理

举例：

Redis：set key value ex 10s

```java
stringRedisTemplate.set("key", "value", 时间大小, 时间单位);
```

Cookie

```
set cookie 过期时间
```



如何让key：value在10s之后，就过期了

定时任务进行轮询，每一秒检查一下，一直到0秒之后，进行delete

自动清理机制，cookie，Redis，expire（本质上还是轮询，还是定时去清理）





### 数目阈值式清理机制

判断缓存中缓存的数量，达到一定值时，对缓存进行清理

阈值：根据项目业务来决定，缓存整体空间的大小，缓存数据量本身的大小

缓存能够使用的空间，缓存中每一条数据的大小

举例：

假设缓存可用空间1G，缓存中数据的平均大小1M，那么可以存储的缓存数据条目数大约为1024个，如果阈值为800左右 ，那么就表示当前缓存中已经存储数据的条目数大于这个阈值的时候就需要对缓存进行清理



#### 数目阈值式清理机制的策略：

##### FIFO（先进先出）

先进先出（ First in First  out），当缓存中的数据达到上限时，优先清理最先写入的数据



只需要一个定长的队列，来存储缓存中的数据，当队列满的时候，从队尾删除对应的数据即可

```java
package cachedesign;

import java.util.LinkedList;
import java.util.Queue;

/**
 * 测试数目阈值式清理机制的清理策略：FIFO（先进先出）
 *
 * @author xcy
 * @date 2023/3/6 - 16:10
 */
public class CacheDesignApplicationTest {
	public static void main(String[] args) {
		Queue<String> queue = new LinkedList<>();
		for (int i = 0; i < 100; i++) {
			setCache(queue, i + "");
		}

	}

	public static void setCache(Queue<String> queue, String cache) {
		int size = queue.size();
 		//设置阈值
		if (size >= 3) {
			queue.poll();
		}

		queue.add(cache);

		System.out.println("缓存中的值如下：");

		for (String q : queue) {
			System.out.println(q);
		}
	}
}

```



##### Random（随机）





##### LRU（最近最少使用）

最近最少使用（Least Recently Used），如果一条数据最近被访问过，则认为它很可能接下来还会被访问；如果一条数据长期没有被访问，则它很可能接下来也不会被访问。

因此，当缓存清理时，优先清理长久未被访问的数据，保留最近被访问过的数据。

通过LinkedHashMap可以通过插入的顺序和访问的顺序，实现：FIFO（先进先出）和LRU（最近最少使用）

具体通过重写removeEldestEntry()的代码进行实现

```java
package com.mashibing.cachedesign.test;

import java.util.LinkedHashMap;
import java.util.Map;

/**
 * 测试数目阈值式清理机制的清理策略：LRU（最近最少使用）
 *
 * @author xcy
 * @date 2023/3/6 - 16:28
 */
public class TestCleanupStrategy_LRU {
	public static void main(String[] args) {
		/**
		 * 构造一个空的<tt>LinkedHashMap<tt>实例，具有指定的初始容量、负载因子和排序模式。
		 * @param initialCapacity 初始容量
		 * @param loadFactor 负载因子
		 * @param accessOrder 排序模式：true对应访问顺序，false对应插入顺序
		 */
		LinkedHashMap<String, String> map = new LinkedHashMap<String, String>(5, 0.75F, true) {
			@Override
			protected boolean removeEldestEntry(Map.Entry<String, String> eldest) {
				//LinkedHashMap的容量大于等于5时，再插入新的元素时就删除旧的元素
				return this.size() >= 5;
			}
		};

		map.put("1", "aa");
		map.put("2", "bb");
		map.put("3", "cc");
		map.put("4", "dd");

		System.out.println("原始顺序：");
		print(map);

		//最近访问的元素，key是2
		String key = "2";
		System.out.println("最近访问的元素是" + key);
		map.get(key);
		print(map);

		//最近访问的元素，key是3
		key = "3";
		System.out.println("最近访问的元素是" + key);
		map.get(key);
		print(map);


		map.put("5", "ee");
		System.out.println("加入新的元素");
		print(map);
	}

	public static void print(LinkedHashMap<String, String> source) {
		source.keySet().iterator().forEachRemaining(System.out::println);
	}
}
```



注意：LinkedHashMap只能在一台服务器上使用



##### LFU（最不经常使用）

最不经常使用 (Least Frequently Used)，优先淘汰访问频率最小的数据





### 软引用清理机制

缓存就是空间换时间的模块

尽量多用缓存空间，用来提高缓存的命中率P



适时地释放空间：GC，当内存紧张的时候才释放

识别出要清理的缓存，然后清除，判断对象是否是垃圾，使用可达性分析法，通过GC的root引用去判断



强引用：哪怕自己报OOM，也不会被GC清理，所以不使用

软引用：当内存空间不足的时候会被回收

弱引用：只要被GC发现，直接回收

虚引用：无法被GC root引用，直接被回收



结论：当空间不足时，进行缓存清理，也就是软引用清理

通过把值 放到 SoftReference  包装中

```java
package com.example.cachetest;

import java.lang.ref.ReferenceQueue;
import java.lang.ref.SoftReference;
import java.util.*;

/**
 * 软引用 缓存 实验
 */
public class CacheSoftReferenceTest {
    public static void main(String[] args) throws InterruptedException {

        soft();
    }
    static void soft(){
        // 缓存
        Map<Integer, SoftRefedStudent> map = new HashMap<Integer, SoftRefedStudent>();
        ReferenceQueue<Student> queue = new ReferenceQueue<Student>();
        int i = 0;
        while (i < 10000000) {
            Student p = new Student();
            map.put(i, new SoftRefedStudent(i, p, queue));
            //p = null;
            SoftRefedStudent pollref = (SoftRefedStudent) queue.poll();
            if (pollref != null) {//找出被软引用回收的对象
                //以key为标志，从map中移除
                System.out.println("回收"+pollref.key);
                map.remove(pollref.key);

                System.out.println(i+"新一轮================================================");
                Iterator<Map.Entry<Integer, SoftRefedStudent>> iterator = map.entrySet().iterator();
                while (iterator.hasNext()){
                    Map.Entry entry = iterator.next();
                    if ((int)entry.getKey() == pollref.key){
                        System.out.println("见鬼了");
                    }
                }
                System.out.println(i+"新一轮================================================");


            }
            i++;
        }
        System.out.println("done");
    }
}


class Student{
    private String name;
    private int age;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }
}

class SoftRefedStudent extends SoftReference<Student> {
    public int key;
    // 第3个参数叫做ReferenceQueue，是用来存储封装的待回收Reference对象的
    /**
     * 当Student对象被回收后，SoftRefedStudent对象会被加入到queue中。
     */
    public SoftRefedStudent(int key, Student referent, ReferenceQueue<Student> q) {
        super(referent, q);
        this.key = key;
    }
}
```



### 缓存清理机制总结

时效性清理 + 数目阈值式 = 定时清理，缓存有一个更新的状态，保证缓存的数目不超过阈值，防止短时间密集型查询导致缓存空间的急剧增大

建议：多思考，形成自己解决问题的框架或者方式，会清晰很多

LRU + 软引用清理 = 保证热点数据，最大限度的提高缓存的命中率P



不推荐单独使用软引用，因为有些数据已经很长时间都没有被访问过了，但是缓存空间没有不足，这些数据应该被回收但是没有被回收，浪费了缓存空间。所以单独使用软引用，导致我们失去了对缓存的控制



缓存清理的目的：提高命中率，节省空间 -> 提升性能



## 缓存的风险

不是组件用的越多越好，在系统中，每增加一个环节，就多一份风险，增加缓存也不例外

在系统架构中，能不使用就不使用，用都是不得已而为之，能不引用的组件就不引用



### 缓存穿透

当用户查询的数据，在缓存中没有，在数据库中也没有

1.链路调用的时间要有

2.查询数据库的时间要有

![image-20230307092911897](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230307092911897.png)

解决方案：

用户在第一次请求的时候，数据提供方返回一个空值，将空值写入到缓存中

为了避免用户多次查询到空值，将空值进行前置

应用场景：

别人恶意攻击你的系统，要将你的系统拖慢，为了避免缓存击穿，返回一个空值

别人通过分析你的系统，访问某个接口，返回一个数据，结果发现该接口没有返回任何数据。此时，如果不去进行预防和处理缓存击穿这种操作，别人不停的调用该接口，那么你的系统会被该接口拖垮的，通过返回一个空值对系统做一层保护



### 缓存雪崩

大量的缓存突然失效或者缓存本身就崩溃了，导致大量的请求倾泻到数据库上，引起数据库的压力骤增



数目阈值式清理机制不会造成缓存雪崩，因为即使是缓存的存储数目超过阈值，也是一个一个进行清理的



1.时效性清理机制会造成缓存雪崩，因为有可能大批量的缓存同时过期，也就是会批量的缓存进行清理

解决方案：缓存时间是固定的，缓存的过期时间设置 = 固定时间（根据业务需求进行分析） + 随机时间，让所有的缓存有一个随机时间



2.软引用清理机制会造成缓存雪崩，因为在某个时间点，当缓存空间严重不足，会删除大量的缓存

解决方案：JVM不受程序员的控制，所以需要配置其它的机制同时生效，比如说LRU，经常访问的数据作为强引用，不经常访问的数据作为软引用，这样在空间不足时，仅仅是不常用的数据会被清理



强引用就是防止大量的请求来时发生雪崩，但是如果强引用太多了，可能会导致OOM



### 缓存击穿

高频率访问的缓存突然失效，导致大量的请求倾泻到数据库上，引起数据库的压力剧增

软引用清理会导致，当空间不足时，清理缓存的时候，我管你是不是高频率访问的缓存，所以说当删除的是高频率访问的缓存也会导致缓存击穿

时效性清理机制会导致，因为缓存的过期跟缓存的高频率访问没有关系，所以说当缓存过期时还是会导致缓存击穿

缓存的更新机制：更新数据库，更新缓存也会导致缓存击穿，因为在缓存被删除的那一刻突然大量的请求进行访问，所以说也会导致缓存击穿



解决方案：

LRU

Read/Write Through

Write Behind

因为这两种方案都是以缓存为主，数据永远都是先存储在缓存中，然后才是数据库



### 缓存风险总结

遇到风险，分析原因，进行解决

分析原因：

-   更新机制
-   清理机制



## 缓存预热

以缓存为主的Read/Write Through和Write Behind

预热：将高频率访问的数据，提前加载到缓存中



解决方案：

系统启动前：加载缓存，让所有的缓存均匀过期时间

电商系统：热门商品，提前加载到缓存，网约车项目：预估价格的计价规则，提前加载到缓存

热门数据：提前加载到缓存





## 服务缓存

请求的数据是根据不同的用户，不同的请求参数，不同的时间等状态生成的结果，结果的差距就会非常大，并且又很少的结果被访问到，缓存的结果就没有太多的意义，分布式系统中，动态数据的生成都有一个过程

个性化的动态的不值得缓存，但是这些数据的生成都有一个过程，可能需要不同的服务模块来完成，尽量在服务器中找那些输出固定响应值的服务做缓存

静态缓存：图片、视频可以提前缓存在用户的客户端

商品的详情页可以缓存在CDN

一般很久都不变的资源可以缓存到客户端：APP的欢迎页，指引页面，固定的视频

一般可能会变的资源可以缓存到服务CDN，运营人员可以操作的那一块数据，开发人员可以控制的地方：新闻的首页

![image-20230307144850078](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230307144850078.png)



## 缓存的位置

缓存来源：

CPU计算速度快，内存计算速度慢，为了避免CPU花费很长的时间来等待内存，于是就出现了缓存

缓存的位置在CPU和内存之间

缓存的容量一般比内存小，但速度会比内存块，解决了CPU和内存速率不匹配的问题



CPU有三级缓存，级别越小越靠近CPU，计算速度越快，容量也更小

L1，最接近CPU，容量最小，计算速度最快，每一个核上都有一个独立的LI

L1有两个：

一个存放数据的，DataCache

一个存放指令的，InstructCache

L2，容量比L1大一些，计算速度比L1慢一些，每一个核上都有一个独立的L2

L3，容量最大，但是计算速度最慢，电脑上同一个CPU插槽，插槽里共享一个L3缓存



缓存的读取过程

获取数据时，会在最快的一级缓存中查找数据，命中就返回，如果缓存没有命中，往下一级缓存去找，直到三级缓存都没有命中，就去内存中获取，缓存一次次没有命中，就代表数据消耗的时间就越长



如何避免CPU等待内存时间，从而导致浪费时间

在内存之前加一个缓存，减少CPU的等待时间

CPU去多做一些事情，多线程

目的：降低成本增加效率



现在的缓存设计领域当中，缓存最常出现在服务器和数据库之间，用来解决数据库响应时间长

缓存不仅仅局限于此

只要任何能够带来系统性能收益和提升的任何地方，都可以加缓存



## 级联系统缓存位置

同一个缓存所处的位置不同，带来的收益也不同

在一个级联系统中，缓存的位置越靠前，越能屏蔽掉系统的压力，其收益也越大

**要想系统性能好，缓存一定要趁早**

![image-20230307152602756](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230307152602756.png)



对缓存的操作放在调用方，如果命中缓存时，就可以节省调用方和被调用方的通信时间

![image-20230307153009480](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230307153009480.png)

对缓存的操作放在被调用方，如果命中缓存时，，一个服务往往可以服务多个前置模块

![image-20230307153308107](%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1.assets/image-20230307153308107.png)

结论：根源业务需求进行选择



## 静态缓存

客户端给出的静态数据的缓存



哪一些数据可以做成静态缓存

1.   静态页面，Apache，录个视频，Apache静态页
2.   通过数据库查询出来的数据
     -   如果每个用户查询出来的都一样，很通用的信息
     -   快递的地址信息，数据库存一份，用的时候放在缓存里
     -   物流信息：省市区

总结：凡是与用户个体无关的，具有较强通用性的数据，都可以做静态缓存，包括数据字典



新闻页面，当用户第一次访问的时候，没有页面，会由页面生成模板生成后放入静态页面缓存模块之中，Apache和Nginx都可以做

访问首页，根据客户端去查，查到之后组成首页的样子，将它作为一个静态文件：HTML，放在Apache或者Nginx里，后面的用户访问的时候就能从Apache或者Nginx中去访问，之后所有的用户再次访问就不需要走后面了

更新操作，已经有缓存页面，如果需要修改首页，后台更改数据之后，如何能够让编辑及时生效

cache-aside，将已缓存的页面删除，重新生成新的缓存页面



静态缓存不适合缓存通用性很差的数据，因为即使是缓存了，缓存命中率很差，缓存就没有意义





## 客户端缓存位置

用户是请求最起始的发起方，而与系统交互的模块称之为客户端，浏览器，PC端，移动端

目的：降低用户的响应时间



1.用户的手和设备之间不能家缓存

2.客户端的缓存是非常重要的，双十一之前，春晚之前，APP都需要更新一下，客户端做一些精简，怕扛不住

充分利用每一个人的手机去减轻服务器的压力，把一些计算功能从服务端转移到客户端，客户端加缓存是一种十分有效的提升系统性能的方式

举例：

网约车并不是下单请求最高，而是预估价格，可以通过用户输入起点和终点计算需要的时长和里程，计价规则也有，完全可以在客户端去做，没有要给服务端发送请求

秒杀系统并不是下单请求最高，而是商品详情页



当系统压力不大的时候，预估价格的数据都存储下来，当请求量增大，比如春节放假前打车时用户量会增大

这种非必须的数据，需要将该数据进行降级

秒杀系统的商品详情页，会有很多东西不能用，比如：个性化推荐，每个用户的喜好是不一样的，那么推荐的内容 也是不一样的，但是在秒杀的时候，每个用户看到的都是一样的，不走个性化推荐，系统做了一次降级，保证优先级高的功能正常运行



举例：

春晚的时候，百度的风巢的资源都让给了百度APP的抢红包的功能，腾出一些服务器



3.浏览器：cookie，相当于Redis，都有过期时间ttl，但是cookie有缺点，客户端请求的时候总是会将cookie也发送给服务端，那么就会增大服务端的压力，所以除非必要，否则不推荐使用cookie做缓存，弊大于利



## 数据库本身的缓存

数据库耗时比较长



数据库的缓存怎么做？

**冗余字段**：

举例：

查询数据涉及到两张表，订单表id，用户表的用户名，需要两次查询动作，可以将用户名放在订单表里，做成冗余字段

**中间表**：

举例：

学生表，课程表，排课表，通过查询学生的课程名称，可以排课表中的课程表里面的课程名称冗余过来，减少对课程表的查询



**查询缓存**：建议不用，MySQL8.0以上抛弃了，query cache，缓存sql语句以及查询结果，如果请求相同的语句，服务器直接从缓存中提取结果，而不是再去解析和执行sql。并且如果表中有一个数据被修改了，那么这个表的所有的缓存都失效了，或者更新表中的数据，只要对表结构或者表数据有任何操作的话，缓存都会失效

对于频繁更改的表，查询缓存是不合适的，对于不常改变的表且有大量相同的sql查询的表，能够节省很大的性能

注意事项：MySQL8.0以下的查询缓存：

select * from user_info;

SELECT * from user_info;

这两条语句默认是不同的，它们的缓存是不能共享的，所以在公司要制定规范，大小写一定要统一

配置缓存，Windows下MySQL根目录的my.ini文件，Linux下my.cnf文件

清理内存碎片

MySQL在服务器高负载的情况下，必须采取措施给服务器减轻压力，减少服务器的IO操作，一般通过优化SQL语句，优化服务器参数的配置等，InnoDB通过缓冲池来缓存数据和索引的，MyISAM通过cache来缓存数据和索引的





历史表：一些业务操作完成之后，比如说10天前的数据可能不用了，那就别再表里占用了，将该数据提前转移走  ，就是需要做统计的非实时性的数据

或者有一些数据写入到数据库中，以后会出一些报表，统计，那么这些出报表、统计的计算方式，可以先将该数据放在后面，相当于将数据先放到历史表里，然后在慢慢计算，就是先规整一下，在慢慢调整

总的来说，就是讲数据放到历史表中，以后的操作：比如报表、统计等等，可以进行延时的操作，而中间的数据存储，相当于一次缓存

问题：新旧数据联合查询怎么办？

新旧数据，排在一起，统计数据进行剥离





## 写缓存

写缓存的位置：位于调用方和数据处理方之间的

写缓存的目的：减少巨量的调用操作，减少数据处理方的压力，起到削峰的作用；因为数据处理方的处理速率是固定的，所以为了防止请求的洪峰到达之后，压垮系统，采用了写缓存



## 写缓存的收益

只要对数据进行修改的操作，都是写操作

原始时间：只有数据处理方处理的时间

引入缓存之后：写缓存的时间，从缓存中读取数据的时间，传输到数据处理方的时间，数据处理方处理的时间

收益方：用户

举例：

假设数据处理方处理的时间为10s，但是现在写缓存的时间2s，写完之后立即响应给客户端，节省了10 - 2 = 8s，减少了用户的响应时间，提高了系统的吞吐量

**总结：**

读缓存和写缓存

读缓存：使用缓存的命中率，替换数据提供方的操作，能减少用户的请求时间，能减少系统的总处理时间

写缓存：花费额外的时间，延迟数据处理方的操作，减少用户的等待，只能减少请求响应的时间，反而会增加系统的总处理时间



## 写缓存的实践



**Redis** 发布订阅

**MQ** 消息队列

**数据库DB** ：给数据库写一堆数据，存储到数据库里面，统计的代码随后读取该数据，生成统计的报表数据。如果写的时候，把后面的代码也执行完，会拉长程序的响应时间

先写数据，剩下的和主业务无关的操作，进行后置（削峰解耦异步）

应用场景：

项目中有些数据需要数据处理方去处理，而且还需要减少用户的响应时间，可以利用上述三个组件进行实现



写缓存的目的：只要能够减少用户的响应时间

写缓存的应用场景：请求峰谷值变化比较明显的、对实时性要求不高的场景

请求的峰谷值忽高忽低，系统数据处理方处理速率是固定的，系统峰值高会将系统压垮，中间加一个写缓存，并且对实时性要求不高，那么就可以对数据处理的操作进行后置

工作场景：抢购系统、竞拍系统进行秒杀的时候，在请求峰值时，写缓存存储请求，降低请求的响应时间，提升系统的吞吐量，在请求谷值时，写缓存会将请求释放出来，让数据处理方慢慢处理



写缓存的问题：请求不是实时处理的，而是异步处理的，在写缓存的时候，要确保这种异步处理的方式是满足系统要求的，比如：在时效性和 一致性方面，不能为了系统的吞吐量而盲目的使用写缓存。



